# Pedagogia Dropout Prediction Â· 2025â€“2026

SystÃ¨me modulaire pour **prÃ©voir le risque de dÃ©crochage** Ã  partir des traces pÃ©dagogiques (projets, tests unitaires, notes). 
Le pipeline couvre : tÃ©lÃ©chargement automatique des donnÃ©es depuis Google Drive, ingestion des donnÃ©es, normalisation en CSV, agrÃ©gation/merge par Ã©tudiant, puis **production d'un modÃ¨le** (clustering + prÃ©diction sÃ©quentielle) avec mÃ©triques.

> Tech: Python 3.12, scikitâ€‘learn, UMAP, Docker (optionnel).gogia Dropout Prediction Â· 2025â€“2026

SystÃ¨me modulaire pour **prÃ©voir le risque de dÃ©crochage** Ã  partir des traces pÃ©dagogiques (projets, tests unitaires, notes). 
Le pipeline couvre : ingestion des donnÃ©es, normalisation en CSV, agrÃ©gation/merge par Ã©tudiant, puis **production dâ€™un modÃ¨le** (clustering + prÃ©diction sÃ©quentielle) avec mÃ©triques.

> Tech: Python 3.12, scikitâ€‘learn, UMAP, Docker (optionnel).

---

## âœ¨ Points clÃ©s

- **Ingestion** depuis les APIs internes (pagination, backâ€‘off 429, export JSON par activitÃ©).
- **Normalisation CSV** + **agrÃ©gation** (verticale par prÃ©fixe) + **fusion horizontale** par `email`.
- **Production modÃ¨le** (script principal) avec paramÃ¨tres explicites : `year`, `n_clusters`, `min_cluster_size`, seuils, fenÃªtres `w1/w2`, alphas.
- **Architecture simple** : tout le code est sous `src/` avec utilitaires dÃ©diÃ©s dans `src/utils/â€¦`.
- **Docker prÃªt Ã  lâ€™emploi** (Dockerfile + dockerâ€‘compose.yml).

---

## ğŸ“ Structure du dÃ©pÃ´t

```
pedagogia-dropout-prediction_2025-2026/
â”œâ”€ src/
â”‚  â”œâ”€ data_loading.py                         # Orchestration pipeline (ingestion â†’ CSV â†’ agrÃ©gat â†’ merge)
â”‚  â”œâ”€ model_production_main.py                # Script principal de production du modÃ¨le
â”‚  â””â”€ utils/
â”‚     â”œâ”€ data_loading_utils/
â”‚     â”‚  â”œâ”€ get_data.py                       # TÃ©lÃ©charge JSON (rÃ©sultats Â« delivery Â») pour une unitÃ©/annÃ©e
â”‚     â”‚  â”œâ”€ all_json_to_csv.py                # Conversion rÃ©cursive JSON â†’ CSV
â”‚     â”‚  â”œâ”€ aggregate_csv.py                  # AgrÃ©gation verticale par Â« prÃ©fixe Â»
â”‚     â”‚  â”œâ”€ merged_csv.py                     # Fusion horizontale par email (ordre imposÃ© si besoin)
â”‚     â”‚  â””â”€ get_activities.py                 # Utilitaire activitÃ©s (pagination)
â”‚     â””â”€ model_production_data_processing_utils.py
â”œâ”€ tests.ipynb
â”œâ”€ requirements.txt
â”œâ”€ Dockerfile
â”œâ”€ docker-compose.yml
â””â”€ README.md
```

---

## ğŸ§° PrÃ©requis

- **Python 3.12+**
- (Optionnel) **Docker** â‰¥ 24
- AccÃ¨s API + **variables dâ€™environnement** (via `.env`) :  
  - `TOKEN_ID`  
  - `TOKEN_PASS`

CrÃ©ez un fichier `.env` Ã  la racineÂ :

```env
TOKEN_ID=xxxxxxxxxxxxxxxx
TOKEN_PASS=yyyyyyyyyyyyyyyy
```

> Les scripts chargent `.env` via `dotenv` et utilisent ces tokens pour lâ€™appel API.

---

## ï¿½ TÃ©lÃ©chargement automatique des donnÃ©es

Le systÃ¨me inclut un **microservice de tÃ©lÃ©chargement** qui rÃ©cupÃ¨re automatiquement le fichier CSV depuis Google Drive.

### Utilisation rapide

**Windows (PowerShell):**
```powershell
.\download_csv.ps1
```

**Linux/Mac (Bash):**
```bash
./download_csv.sh
```

**Ou via Docker Compose:**
```bash
docker compose up csv-downloader --build
```

Le fichier sera tÃ©lÃ©chargÃ© dans `./data/DATA_2025_pred_proj.csv`.

### Configuration manuelle

Vous pouvez aussi utiliser le microservice directement :

```bash
python src/csv_downloader.py \
  --url "https://drive.google.com/file/d/1ZeJ2f1qfpENc-gIwYGiQsVM5nCGaTQkG/view?usp=drive_link" \
  --output "./data/DATA_2025_pred_proj.csv" \
  --retries 3 \
  --verify
```

---

## ï¿½ğŸš€ Installation rapide (sans Docker)

```bash
# 1) Cloner et se placer dans le dossier
git clone <votre-repo> pedagogia-dropout-prediction_2025-2026
cd pedagogia-dropout-prediction_2025-2026

# 2) CrÃ©er un venv et installer
python -m venv .venv
# Windows: .venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

pip install -r requirements.txt
```

---

## ğŸ”„ Pipeline de donnÃ©es (ingestion â†’ CSV â†’ agrÃ©gat â†’ merge)

Vous pouvez soit appeler les sousâ€‘scripts, soit piloter via `src/data_loading.py`. Ciâ€‘dessous, la version **pas Ã  pas** (recommandÃ© pour Ãªtre explicite sur les chemins).

### 1) TÃ©lÃ©charger les JSON (*results Â« delivery Â»*)

ScriptÂ : `src/utils/data_loading_utils/get_data.py`

Arguments dÃ©tectÃ©sÂ : `--year` (int, requis), `--unit` (str, requis), `--source` (intra/extra, dÃ©faut *intra*), `--output` (dossier de sortie).

```bash
python -u src/utils/data_loading_utils/get_data.py   --year 2024   --unit B-CPE-100   --source intra   --output data/data_json
```

> â—ï¸Si vous voyez lâ€™erreur `the following arguments are required: --year, --unit`, passez bien ces 2 paramÃ¨tres (ils sont **requis**).

### 2) Convertir JSON â†’ CSV

```bash
python -u src/utils/data_loading_utils/all_json_to_csv.py   --input data/data_json   --output data_csv
```

### 3) AgrÃ©ger verticalement (par Â« prÃ©fixe Â» de fichier)

Le prÃ©fixe est tout avant le **dernier** underscore `_`. Tous les fichiers partageant ce prÃ©fixe sont concatÃ©nÃ©s.

```bash
python -u src/utils/data_loading_utils/aggregate_csv.py   --indir data_csv   --outdir agg   --filter "*.csv"
```

### 4) Fusion horizontale par `email`

```bash
python -u src/utils/data_loading_utils/merged_csv.py   --indir agg   --out data/DATA.csv
```

> Ã€ lâ€™issue de ces 4 Ã©tapes, vous disposez dâ€™un **master CSV** : `data/DATA.csv`

---

## ğŸ¤– Production du modÃ¨le

ScriptÂ : `src/model_production_main.py`  
Arguments disponiblesÂ : `--year`, `--n_clusters`, `--min_cluster_size`, `--data_file`, `--threshold`, `--w1`, `--w2`, `--alpha1`, `--alpha2`.

Exemple minimal reproductibleÂ :

```bash
python -u src/model_production_main.py   --year 2024   --n_clusters 10   --min_cluster_size 20   --data_file data/DATA.csv   --threshold 10.0   --w1 2 --w2 2   --alpha1 0.05 --alpha2 0.05
```

> Notes :
> - `n_clusters` et `min_cluster_size` contrÃ´lent le **clustering** amont.
> - `w1/w2` et `alpha1/alpha2` contrÃ´lent la **prÃ©diction sÃ©quentielle** (p. ex. variantes SPCI) et les budgets dâ€™alpha.
> - `threshold` peut servir de seuil mÃ©tier (ex. dÃ©cision dâ€™alerte).

---

## ğŸ§ª ReproductibilitÃ©

- Versions **pinnÃ©es** dans `requirements.txt`.
- Fixez vos graines globales (ex. `RANDOM_STATE=42`) au niveau des scripts si besoin.
- Exportez vos **artefacts** (modÃ¨les, mÃ©triques) dans un dossier versionnÃ© (`models/`, `reports/`).

---

## ğŸ³ ExÃ©cution via Docker (optionnel)

### Build image

```bash
docker build -t pedagogia-dropout:latest .
```

### Lancer le pipeline dans un conteneur

```bash
docker run --rm -it   --env-file .env   -v "$(pwd)/data:/app/data"   -v "$(pwd)/models:/app/models"   pedagogia-dropout:latest   python -u src/utils/data_loading_utils/get_data.py --year 2024 --unit B-CPE-100 --output data/data_json
```

> Vous pouvez ensuite enchaÃ®ner les Ã©tapes 2â†’4, puis lancer `model_production_main.py` de la mÃªme faÃ§on.

> **docker-compose** : un fichier `docker-compose.yml` est fourni ; adaptez les volumes `data/` et `models/` selon votre environnement.

---

## ğŸ—‚ï¸ DonnÃ©es attendues (rÃ©sumÃ©)

- **EntrÃ©es** : JSON par activitÃ© \â†’ CSV normalisÃ©s \â†’ agrÃ©gats par prÃ©fixe \â†’ merge final par `email`.
- **Sortie** : `data/DATA.csv` (master), + artefacts de modÃ¨les dans `models/` (si configurÃ©).

---

## â“DÃ©pannage

- `Required: --year / --unit` â†’ passez explicitement ces arguments (voir Ã©tapes ciâ€‘dessus).
- Taux HTTP **429** â†’ le client gÃ¨re un **backâ€‘off exponentiel** automatiquement, mais vous pouvez relancer.
- Encodage CSV â†’ assurezâ€‘vous dâ€™utiliser UTFâ€‘8 lors de toute postâ€‘Ã©dition manuelle.

---

## ğŸ“œ Licence & crÃ©dits

- Licence : Ã  prÃ©ciser (MIT/Apacheâ€‘2.0 ?).  
- Auteurs principaux : Ã©quipe pÃ©dagogia (2025â€“2026).  
- Contributions bienvenues via *Pull Requests*.

---

## ğŸ§­ Roadmap (suggestions)

- Ajout dâ€™un **Makefile** (targets : `data`, `csv`, `agg`, `merge`, `train`).
- Export automatique des **mÃ©triques** (JSON + tableau Markdown).
- Option `--units` multiple pour `get_data.py` (bouclage sur plusieurs codes).
- Ajout dâ€™un exemple de **jeu de donnÃ©es synthÃ©tique** pour tests rapides.
