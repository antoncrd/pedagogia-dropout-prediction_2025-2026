{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from mapie.metrics import (\n",
    "    classification_coverage_score,\n",
    "    classification_mean_width_score\n",
    ")\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.model_production_data_processing_utils import cluster_with_min_size\n",
    "import umap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "root = Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafe082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_production_main import load_and_preprocess_data, prepare_features\n",
    "from utils.model_production_data_processing_utils import compute_threshold_kmeans, build_X_s, build_umap_windows_by_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28972e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = load_and_preprocess_data(root / \"data/DATA.csv\", 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e256ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25 = load_and_preprocess_data(root / \"data/DATA_2025.csv\", 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df25.columns:\n",
    "    if c.endswith(\"city\"):\n",
    "        print(c)\n",
    "    if c.startswith(\"city\"):\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734228c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25 = load_and_preprocess_data(root / \"data/DATA_2025.csv\", 25)\n",
    "df2025 = pd.read_csv(root / \"data/DATA_2025.csv\")\n",
    "X = prepare_features(df25, 2025)\n",
    "df2, info = cluster_with_min_size(\n",
    "    df25, X, n_clusters=4, min_cluster_size=50, random_state=42\n",
    ")\n",
    "mark_cols = [c for c in df25.columns if c.endswith(\"mark\")]\n",
    "prefixes = list(dict.fromkeys(c.rsplit(\"_\",1)[0] for c in mark_cols))\n",
    "static_cols = []\n",
    "X_CP = build_X_s(df2.fillna(0), prefixes, static_cols, 1)\n",
    "mod_CP = joblib.load(root / \"models\" / \"models_clustering_24.joblib\")\n",
    "key = ('GB', 1, \"vanilla\")\n",
    "model_CP = mod_CP[key]\n",
    "yp_van, yps_van = model_CP.predict(X_CP, alpha=0.1)  # partition=df2['clusters'])\n",
    "pset_van = yps_van[:, :, 0].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pset_to_label(pset: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Map conformal prediction sets (boolean array of shape (n, 2))\n",
    "    to integer labels:\n",
    "      [True, False]  -> 0\n",
    "      [False, True]  -> 1\n",
    "      [True, True]   -> 2\n",
    "    \"\"\"\n",
    "    labels = np.full(pset.shape[0], -1, dtype=int)  # init with -1 (invalid)\n",
    "    labels[(pset[:, 0] == True) & (pset[:, 1] == False)] = 0\n",
    "    labels[(pset[:, 0] == False) & (pset[:, 1] == True)] = 1\n",
    "    labels[(pset[:, 0] == True) & (pset[:, 1] == True)] = 2\n",
    "    return labels\n",
    "\n",
    "labels_van = map_pset_to_label(pset_van)\n",
    "df25['prediction1'] = labels_van"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcpool = df25[[c for c in df25.columns if c.startswith(\"G-CPE-100\")]]\n",
    "pat = re.compile(r\"B-CPE-100_cpoolday\\d+_\\d{2} - task\\d+_passed\")\n",
    "cols_keep = [c for c in dfcpool.columns if not pat.match(c)]\n",
    "dfcpool_mark = dfcpool[cols_keep]\n",
    "X = dfcpool_mark.fillna(0)\n",
    "ta = [c for c in X.columns if c.endswith('passed')]\n",
    "X_bin = X[ta]\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=8,          # ↓ pour plus local\n",
    "    min_dist=0.25,          # ↑ étale un peu les amas\n",
    "    spread=1.0,\n",
    "    n_components=2,\n",
    "    metric=\"hamming\",\n",
    "    random_state=42,\n",
    ")\n",
    "emb = reducer.fit_transform(X_bin)\n",
    "\n",
    "labels = KMeans(n_clusters=7, n_init=\"auto\", random_state=42).fit_predict(emb)\n",
    "\n",
    "df25['UMAP1'] = emb[:, 0]\n",
    "df25['UMAP2'] = emb[:, 1]\n",
    "df25['clusters'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6558c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df25.columns:\n",
    "    if c.endswith('mark'):\n",
    "        df25[c] = df2025[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25['G-CPE-100_cpoolday01_mark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "df25.to_csv(\"/data/DATA_2025_pred_proj.csv\", index=False, encoding=\"utf-8\")\n",
    "FileLink(\"/data/DATA_2025_pred_proj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,6))\n",
    "unique = np.unique(labels)\n",
    "for lab in unique:\n",
    "    mask = labels == lab\n",
    "    plt.scatter(emb[mask, 0], emb[mask, 1], s=12, label=f\"Cluster {lab}\" if lab!=-1 else \"Bruit (-1)\", alpha=0.8)\n",
    "plt.xlabel(\"UMAP-1\")\n",
    "plt.ylabel(\"UMAP-2\")\n",
    "plt.title('title')\n",
    "plt.legend(markerscale=1.5, fontsize=9, frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def to_bool2_from_spci_intervals(intervals, thr):\n",
    "    \"\"\"\n",
    "    intervals: (n_samples, 2) with (L, U)\n",
    "    Retourne une matrice booléenne (n_samples, 2) codant l'ensemble {0},{1},{0,1}.\n",
    "    Col 0 ⇔ contient '0' ; Col 1 ⇔ contient '1'.\n",
    "    Règle:\n",
    "      U<thr  -> {1}\n",
    "      L>thr  -> {0}\n",
    "      sinon  -> {0,1}\n",
    "    \"\"\"\n",
    "    L = intervals[:, 0]\n",
    "    U = intervals[:, 1]\n",
    "    both = (~(U < thr)) & (~(L > thr))   # ni U<thr ni L>thr -> {0,1}\n",
    "    inc0 = (L > thr) | both\n",
    "    inc1 = (U < thr) | both\n",
    "    return np.stack([inc0, inc1], axis=1)\n",
    "\n",
    "## WORKING CELL\n",
    "\n",
    "y_true = pd.read_csv(root / \"data/y_true_24\")\n",
    "mark_cols = [c for c in df1.columns if c.endswith(\"mark\")]\n",
    "prefixes = list(dict.fromkeys(c.rsplit(\"_\",1)[0] for c in mark_cols))\n",
    "static_cols = []\n",
    "\n",
    "threshold = compute_threshold_kmeans(df1)\n",
    "# Prepare features\n",
    "X = prepare_features(df1, 24)\n",
    "\n",
    "# Perform clustering\n",
    "df2, info = cluster_with_min_size(\n",
    "    df1, X, n_clusters=4, min_cluster_size=50, random_state=42\n",
    ")\n",
    "\n",
    "w1 = 3\n",
    "w2 = 10\n",
    "\n",
    "covs = {}\n",
    "wids = {}\n",
    "covs_spci = {}\n",
    "wids_spci = {}\n",
    "covs_comb = {}\n",
    "wids_comb = {}\n",
    "\n",
    "Xt, keys, X_arr, y_arr = build_umap_windows_by_suffix(\n",
    "        df1, w=w2, H=0, target_col_idx=3, verbose=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(root / \"data/DATA_SPCI_ng_24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e98b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mod_SPCI = joblib.load(root / \"models\" / \"models_SPCI_lg_24.joblib\")\n",
    "mod_comb = joblib.load(root / \"models\" / \"models_comb1_24.joblib\")\n",
    "mod_CP = joblib.load(root / \"models\" / \"models_clustering_24.joblib\")\n",
    "mod_CP_ng = joblib.load(root / \"models\" / \"models_clustering_SPCI_ng_24.joblib\")\n",
    "mod_comb_ng = joblib.load(root / \"models\" / \"models_comb2_24.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca90a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_comb.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e40cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_arr = np.asarray(y_true).ravel().astype(int)\n",
    "alpha = 0.1\n",
    "max_N = 22\n",
    "\n",
    "for base_model in ['GB']:\n",
    "    for n in tqdm(range(1, max_N)):\n",
    "        key = (base_model, n, \"vanilla\")\n",
    "        X_CP = build_X_s(df2.fillna(0), prefixes, static_cols, n)\n",
    "        model_CP = mod_CP[key]\n",
    "        yp_van, yps_van = model_CP.predict(X_CP, alpha=alpha)  # partition=df2['clusters'])\n",
    "        pset_van = yps_van[:, :, 0].astype(bool)\n",
    "        cov = classification_coverage_score(y_true_arr, pset_van)\n",
    "        wid = classification_mean_width_score(pset_van)\n",
    "        covs[(base_model, n)] = cov\n",
    "        wids[(base_model, n)] = wid\n",
    "        if n <= w2:\n",
    "            print(f\"n={n:2d} | MCP: cov={cov:.3f}, wid={wid:.3f} | \")\n",
    "        # Prédictions SPCI et combinées pour n > w2\n",
    "        if n > w2: ## BELEK INDEX\n",
    "            # Prédictions SPCI\n",
    "            model_SPCI = mod_SPCI[n]\n",
    "            X_SPCI = X_arr[n - w2]  # Ajustement de l'index comme dans train_combined_models\n",
    "            intervals = np.array([model_SPCI.predict_interval(x) for x in X_SPCI], dtype=float)\n",
    "            pset_spci = to_bool2_from_spci_intervals(intervals, threshold)\n",
    "            cov_spci = classification_coverage_score(y_true_arr, pset_spci)\n",
    "            wid_spci = classification_mean_width_score(pset_spci)\n",
    "            covs_spci[(base_model, n)] = cov_spci\n",
    "            wids_spci[(base_model, n)] = wid_spci\n",
    "            \n",
    "            # Prédictions combinées avec le modèle gate\n",
    "            gate_model = mod_comb[(base_model, n)]\n",
    "            \n",
    "            # Calcul des features pour le gate (comme dans train_combined_models)\n",
    "            w_cls = pset_van.sum(axis=1)  # Largeur des prédictions MCP\n",
    "            w_spc = pset_spci.sum(axis=1)  # Largeur des prédictions SPCI\n",
    "            diff = w_cls - w_spc\n",
    "            \n",
    "            # Construction de X_gate avec les mêmes features que lors de l'entraînement\n",
    "            meta_features = np.column_stack([w_cls, w_spc, diff])\n",
    "            X_gate = np.hstack([X_CP, meta_features])\n",
    "            \n",
    "            # Prédiction du gate : 0=MCP, 1=SPCI, 2=union\n",
    "            gate_preds = gate_model.predict(X_gate)\n",
    "            \n",
    "            # Construction des prediction sets combinés\n",
    "            pset_combined = np.zeros_like(pset_van, dtype=bool)\n",
    "            \n",
    "            for i in range(len(gate_preds)):\n",
    "                if gate_preds[i] == 0:  # Utiliser MCP\n",
    "                    pset_combined[i] = pset_van[i]\n",
    "                elif gate_preds[i] == 1:  # Utiliser SPCI\n",
    "                    pset_combined[i] = pset_spci[i]\n",
    "                else:  # gate_preds[i] == 2, utiliser l'union\n",
    "                    pset_combined[i] = pset_van[i] | pset_spci[i]\n",
    "            \n",
    "            # Calcul des métriques pour le modèle combiné\n",
    "            cov_comb = classification_coverage_score(y_true_arr, pset_combined)\n",
    "            wid_comb = classification_mean_width_score(pset_combined)\n",
    "            covs_comb[(base_model, n)] = cov_comb\n",
    "            wids_comb[(base_model, n)] = wid_comb\n",
    "            \n",
    "            # Affichage optionnel des résultats\n",
    "            print(f\"n={n:2d} | MCP: cov={cov:.3f}, wid={wid:.3f} | \"\n",
    "                  f\"SPCI: cov={cov_spci:.3f}, wid={wid_spci:.3f} | \"\n",
    "                  f\"Comb: cov={cov_comb:.3f}, wid={wid_comb:.3f}\")\n",
    "            \n",
    "            # Statistiques sur les décisions du gate\n",
    "            gate_choices, gate_counts = np.unique(gate_preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_arr = np.asarray(y_true).ravel().astype(int)\n",
    "alpha = 0.1\n",
    "max_N = 22\n",
    "\n",
    "for base_model in ['GB']:\n",
    "    for n in tqdm(range(1, max_N)):\n",
    "        key = (base_model, n, \"vanilla\")\n",
    "        X_CP = build_X_s(df3.fillna(0), prefixes, static_cols, n)\n",
    "        model_CP_ng = mod_CP_ng[key]\n",
    "        yp_van, yps_van = model_CP_ng.predict(X_CP, alpha=alpha)  # partition=df2['clusters'])\n",
    "        pset_van = yps_van[:, :, 0].astype(bool)\n",
    "        cov = classification_coverage_score(y_true_arr, pset_van)\n",
    "        wid = classification_mean_width_score(pset_van)\n",
    "        covs[(base_model, n)] = cov\n",
    "        wids[(base_model, n)] = wid\n",
    "        if n <= w2:\n",
    "            print(f\"n={n:2d} | MCP: cov={cov:.3f}, wid={wid:.3f} | \")\n",
    "        # Prédictions SPCI et combinées pour n > w2\n",
    "        if n > w2: ## BELEK INDEX\n",
    "            # Prédictions SPCI\n",
    "            model_SPCI = mod_SPCI[n]\n",
    "            X_SPCI = X_arr[n - w2]  # Ajustement de l'index comme dans train_combined_models\n",
    "            intervals = np.array([model_SPCI.predict_interval(x) for x in X_SPCI], dtype=float)\n",
    "            pset_spci = to_bool2_from_spci_intervals(intervals, threshold)\n",
    "            cov_spci = classification_coverage_score(y_true_arr, pset_spci)\n",
    "            wid_spci = classification_mean_width_score(pset_spci)\n",
    "            covs_spci[(base_model, n)] = cov_spci\n",
    "            wids_spci[(base_model, n)] = wid_spci\n",
    "            \n",
    "            # Prédictions combinées avec le modèle gate\n",
    "            gate_model = mod_comb_ng[(base_model, n)]\n",
    "            \n",
    "            # Calcul des features pour le gate (comme dans train_combined_models)\n",
    "            w_cls = pset_van.sum(axis=1)  # Largeur des prédictions MCP\n",
    "            w_spc = pset_spci.sum(axis=1)  # Largeur des prédictions SPCI\n",
    "            diff = w_cls - w_spc\n",
    "            \n",
    "            # Construction de X_gate avec les mêmes features que lors de l'entraînement\n",
    "            meta_features = np.column_stack([w_cls, w_spc, diff])\n",
    "            X_gate = np.hstack([X_CP, meta_features])\n",
    "            \n",
    "            # Prédiction du gate : 0=MCP, 1=SPCI, 2=union\n",
    "            gate_preds = gate_model.predict(X_gate)\n",
    "            \n",
    "            # Construction des prediction sets combinés\n",
    "            pset_combined = np.zeros_like(pset_van, dtype=bool)\n",
    "            \n",
    "            for i in range(len(gate_preds)):\n",
    "                if gate_preds[i] == 0:  # Utiliser MCP\n",
    "                    pset_combined[i] = pset_van[i]\n",
    "                elif gate_preds[i] == 1:  # Utiliser SPCI\n",
    "                    pset_combined[i] = pset_spci[i]\n",
    "                else:  # gate_preds[i] == 2, utiliser l'union\n",
    "                    pset_combined[i] = pset_van[i] | pset_spci[i]\n",
    "            \n",
    "            # Calcul des métriques pour le modèle combiné\n",
    "            cov_comb = classification_coverage_score(y_true_arr, pset_combined)\n",
    "            wid_comb = classification_mean_width_score(pset_combined)\n",
    "            covs_comb[(base_model, n)] = cov_comb\n",
    "            wids_comb[(base_model, n)] = wid_comb\n",
    "            \n",
    "            # Affichage optionnel des résultats\n",
    "            print(f\"n={n:2d} | MCP: cov={cov:.3f}, wid={wid:.3f} | \"\n",
    "                  f\"SPCI: cov={cov_spci:.3f}, wid={wid_spci:.3f} | \"\n",
    "                  f\"Comb: cov={cov_comb:.3f}, wid={wid_comb:.3f}\")\n",
    "            \n",
    "            # Statistiques sur les décisions du gate\n",
    "            gate_choices, gate_counts = np.unique(gate_preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv(root /\"data/DATA_2025_pred_proj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
